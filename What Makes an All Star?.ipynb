{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Makes an All Star?\n",
    "Development of a machine learning model to predict which RuPaul's Drag Race contestants are most likely to be selected for an All Stars Season based on their performance in previous seasons. **\n",
    "\n",
    "**Note:** For the purposes of this exploration, I use the terminology \"selected\" to describe a contestant who has competed in previous seasons who is competing in the target All Stars season. I am aware that not all contestants who are selected for All Stars accept and that this information is not widely distributed, so it is impossible to obtain accurate data on which contestants are selected for All Stars. \"Selected for All Stars\" in this context should therefore be read as a shorthand \"selected and accepted an invitation to compete in All Stars\". This is further discussed in the \"Reviewing sample output and refining the input parameters\" section under \"Ineligibility and declined invitations\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieving input data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run prep module to get data of contestant performance and All Stars selection/performance for All Stars Seasons 1-4 scraped from Wikipedia and cleaned for analysis. (The All_Stars_Data_Prep Python script can be found in the GitHub repository for this project.)\n",
    "\n",
    "Additionally, set a seed value to be used throughout the procedure for splitting and bootstrapping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import All_Stars_Data_Prep as all_stars_prep\n",
    "model_data = all_stars_prep.get_all_stars_selection_model_data(range(1,5))\n",
    "\n",
    "seed_value = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load function to get Pearson correlations and p-values to explore which features might be best used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pearson_correlations (model_data, dv, feature_columns):\n",
    "\n",
    "    # Create output dataframe\n",
    "    df = pd.DataFrame(columns=['Independent Variable', 'Correlation', 'P-Value'])\n",
    "    \n",
    "    # For each independent variable in the feature columns, get Pearson correlation/p-value and add to dataframe\n",
    "    for iv in feature_columns:\n",
    "        [corr, pval] = pearsonr(model_data[iv], model_data[dv])\n",
    "        new_row = [iv, corr, pval]\n",
    "        df.loc[df.shape[0] + 1] = new_row\n",
    "        \n",
    "    # Sort by p-value\n",
    "    df = df.sort_values(by=['P-Value'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Correlations***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore correlations to see what independent variables are correlated with a contestant being selected for All Stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Independent Variable</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Season Miss Congeniality</td>\n",
       "      <td>0.189120</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>0.148623</td>\n",
       "      <td>0.003969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years Since Last Competed</td>\n",
       "      <td>-0.144958</td>\n",
       "      <td>0.004972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Guest</td>\n",
       "      <td>-0.120837</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Season Winner</td>\n",
       "      <td>-0.111353</td>\n",
       "      <td>0.031322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Safe</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>0.033347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Season Runner-Up</td>\n",
       "      <td>0.102309</td>\n",
       "      <td>0.048027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eliminated</td>\n",
       "      <td>-0.098907</td>\n",
       "      <td>0.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Total Appearances</td>\n",
       "      <td>0.091991</td>\n",
       "      <td>0.075594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>0.051252</td>\n",
       "      <td>0.322911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>0.488503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low</td>\n",
       "      <td>-0.008554</td>\n",
       "      <td>0.869039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Independent Variable  Correlation   P-Value\n",
       "10   Season Miss Congeniality     0.189120  0.000235\n",
       "2                        High     0.148623  0.003969\n",
       "12  Years Since Last Competed    -0.144958  0.004972\n",
       "7                       Guest    -0.120837  0.019407\n",
       "8               Season Winner    -0.111353  0.031322\n",
       "3                        Safe     0.110064  0.033347\n",
       "9            Season Runner-Up     0.102309  0.048027\n",
       "6                  Eliminated    -0.098907  0.055998\n",
       "11          Total Appearances     0.091991  0.075594\n",
       "5                      Bottom     0.051252  0.322911\n",
       "1                         Win     0.035927  0.488503\n",
       "4                         Low    -0.008554  0.869039"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [ 'Win', 'High', 'Safe', 'Low', 'Bottom', 'Eliminated', 'Guest', \n",
    "                 'Season Winner', 'Season Runner-Up', 'Season Miss Congeniality',\n",
    "                 'Total Appearances', 'Years Since Last Competed' ]\n",
    "\n",
    "pcorr = get_pearson_correlations(model_data, 'Competed', feature_cols)\n",
    "pcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a viewer of the show, this is quite an interesting list of correlations.\n",
    "\n",
    "The independent variable with the strongest correlation and the lowest p-value to whether or not a contestant is selected to compete in an All Stars season is whether or not the contestant was crowned Miss Congeniality in a main season. This may have something to do with the \"fan favourite\" nature of the award (as noted by Trinity the Tuck in the season 9 reunion) and, upon examination, only 3 of the 11 eligible Miss Congeniality winners - Ivy Winters, Cynthia Lee Fontaine, and Nina West (excluding Heidi N Closet who was awarded Miss Congeniality after the most recent All Stars cast was already announced) - did not return for an All Stars Season. Of these, Cynthia Lee Fontaine was asked to return for a main season (season 9) and Nina West has only been eligible for one selection round and may be selected for subsequent seasons. This correlation makes a lot of sense in the context of the shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Confusion matrix for subset of independent variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of feature names to be used in an initial model, selecting those with a p-value of less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Season Miss Congeniality',\n",
       " 'High',\n",
       " 'Years Since Last Competed',\n",
       " 'Guest',\n",
       " 'Season Winner',\n",
       " 'Safe',\n",
       " 'Season Runner-Up']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols_selected = list(pcorr.loc[pcorr['P-Value'] < 0.05]['Independent Variable'])\n",
    "feature_cols_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load function to get confusion matrix for a selected set of feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix (model_data, feature_cols, dependent_variable, seed_val=0, test_size=0.25, solver='liblinear'):  \n",
    "    \n",
    "    # Split into independent and dependent variables\n",
    "    X = model_data[feature_cols]\n",
    "    y = model_data[dependent_variable]\n",
    "    \n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed_val)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    lr = LogisticRegression(solver=solver)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine confusion matrix for the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85,  0],\n",
       "       [ 9,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = get_confusion_matrix(model_data, feature_cols_selected, 'Competed')\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, at 89.36%, the overall accuracy of the model is high, the recall of the two classification is 0% and 100% (for outcomes of \"selected\" and \"not selected\" respectively). The model is consistently predicting an outcome of 0 for whether or not a contestant is selected to compete.\n",
    "\n",
    "This behaviour indicates that my dataset is imbalanced. An imbalanced dataset is one where records with one output classification (the minority) are vastly outnumbered by records with another output classification (the majority), resulting in the model predicting the majority output every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many records belong to each output class to get the ratio of class instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data[model_data['Competed']==1].count()['Contestant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data[model_data['Competed']==0].count()['Contestant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall class ratio is 39:337 - just over 10% of the records belong to the minority class (contestants selected for the All Stars season).\n",
    "\n",
    "This is consistent with the nature of this dataset, since out of at least 46 contestants that could be selected for an All Stars season (up to almost 130 for All Stars Season 4), only 10-12 contestants are selected, making a complete dataset imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset will need to be rebalanced, which I will try to achieve by over-sampling. I have decided to use over-sampling in this case as the overall number of records is less than 500 and under-sampling is best used where there is a large number of records (>10,000). For this, I will use the random oversampling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rebalancing by oversampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import imblearn library and create function to get an oversampled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from imblearn import over_sampling as imbsample\n",
    "\n",
    "def get_oversampled_df (model_data, feature_columns, dependent_variable, sampling_strategy='minority', seed_val=0):\n",
    "\n",
    "    # Get dependent and independent variables\n",
    "    X = model_data[feature_columns]\n",
    "    y = model_data[dependent_variable]\n",
    "    \n",
    "    # Create an oversample object and fit it to the data\n",
    "    oversample_obj = imbsample.RandomOverSampler(sampling_strategy=sampling_strategy, random_state=seed_val)\n",
    "    X_over, y_over = oversample_obj.fit_resample(X, y)\n",
    "    \n",
    "    # Combine variables into a single dataframe for output\n",
    "    oversampled_df = X_over\n",
    "    oversampled_df['Competed'] = y_over\n",
    "    \n",
    "    return oversampled_df\n",
    "\n",
    "oversampled_df = get_oversampled_df(model_data, feature_cols, 'Competed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the confusion matrix function to allow for oversampling of training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_matrix (model_data, feature_cols, dependent_variable, seed_val=0, test_size=0.25, \n",
    "                          solver='liblinear', oversample_training_data=False, sampling_strategy='minority'):  \n",
    "    \n",
    "    # Split into independent and dependent variables\n",
    "    X = model_data[feature_cols]\n",
    "    y = model_data[dependent_variable]\n",
    "    \n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed_val)\n",
    "    \n",
    "    # Oversample training data if specified\n",
    "    oversample_obj = imbsample.RandomOverSampler(sampling_strategy=sampling_strategy, random_state=seed_val)\n",
    "    X_train, y_train = oversample_obj.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    lr = LogisticRegression(solver=solver)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Correlations with oversampled data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run correlations with oversampled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Independent Variable</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Years Since Last Competed</td>\n",
       "      <td>-0.285527</td>\n",
       "      <td>4.910271e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Season Miss Congeniality</td>\n",
       "      <td>0.264830</td>\n",
       "      <td>3.239433e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>4.941161e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Season Winner</td>\n",
       "      <td>-0.238290</td>\n",
       "      <td>4.192707e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eliminated</td>\n",
       "      <td>-0.222549</td>\n",
       "      <td>5.781456e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Guest</td>\n",
       "      <td>-0.190145</td>\n",
       "      <td>7.126181e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Season Runner-Up</td>\n",
       "      <td>0.179680</td>\n",
       "      <td>2.863899e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Safe</td>\n",
       "      <td>0.159656</td>\n",
       "      <td>3.302550e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Total Appearances</td>\n",
       "      <td>0.152788</td>\n",
       "      <td>7.163963e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bottom</td>\n",
       "      <td>0.077942</td>\n",
       "      <td>4.371890e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Win</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>3.123389e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low</td>\n",
       "      <td>-0.028547</td>\n",
       "      <td>4.607042e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Independent Variable  Correlation       P-Value\n",
       "12  Years Since Last Competed    -0.285527  4.910271e-14\n",
       "10   Season Miss Congeniality     0.264830  3.239433e-12\n",
       "2                        High     0.262642  4.941161e-12\n",
       "8               Season Winner    -0.238290  4.192707e-10\n",
       "6                  Eliminated    -0.222549  5.781456e-09\n",
       "7                       Guest    -0.190145  7.126181e-07\n",
       "9            Season Runner-Up     0.179680  2.863899e-06\n",
       "3                        Safe     0.159656  3.302550e-05\n",
       "11          Total Appearances     0.152788  7.163963e-05\n",
       "5                      Bottom     0.077942  4.371890e-02\n",
       "1                         Win     0.039090  3.123389e-01\n",
       "4                         Low    -0.028547  4.607042e-01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcorr = get_pearson_correlations(oversampled_df, 'Competed', feature_cols)\n",
    "pcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that many more of the correlations are statistically significant. Once again, I'm going to select the feature columns where the p-value is less than 0.05 (5.0e-2) as a starting point and work on forward and backward subset selection from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Years Since Last Competed',\n",
       " 'Season Miss Congeniality',\n",
       " 'High',\n",
       " 'Season Winner',\n",
       " 'Eliminated',\n",
       " 'Guest',\n",
       " 'Season Runner-Up',\n",
       " 'Safe',\n",
       " 'Total Appearances',\n",
       " 'Bottom']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols_selected = list(pcorr.loc[pcorr['P-Value'] < 0.05]['Independent Variable'])\n",
    "feature_cols_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Confusion matrix for subset of independent variables with oversampled data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine confusion matrix with the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 13],\n",
       "       [ 3,  6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = get_confusion_matrix(model_data, feature_cols_selected, 'Competed', oversample_training_data=True)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy with the oversampled data is 78.72%, with a recall of 60.0% for the group that were selected to compete and 80.95% for the group that were not selected. While the overall accuracy and the recall for the non-competing class have dropped, the recall for the class selected to compete in All Stars has increased dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve selected model as an object**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the get_confusion_matrix() function to create a function returning the model itself rather than the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model (model_data, feature_cols, dependent_variable, seed_val=0, test_size=0.25, \n",
    "               solver='liblinear', oversample_training_data=False, sampling_strategy='minority'):  \n",
    "    \n",
    "    # Split into independent and dependent variables\n",
    "    X = model_data[feature_cols]\n",
    "    y = model_data[dependent_variable]\n",
    "    \n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed_val)\n",
    "    \n",
    "    # Oversample training data if specified\n",
    "    oversample_obj = imbsample.RandomOverSampler(sampling_strategy=sampling_strategy, random_state=seed_val)\n",
    "    X_train, y_train = oversample_obj.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    lr = LogisticRegression(solver=solver)\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model(model_data, feature_cols_selected, 'Competed', oversample_training_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions about the contestants selected for All Stars Season 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model data for All Stars Season 5 only, then manually add in which contestants have been selected (the data is not yet on Wikipedia in a form that can be retrieved by Wikipedia_Web_Scrape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_data_season_5 = all_stars_prep.get_all_stars_selection_model_data(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted values for All Stars Season 5 model data and print the names of contestants predicted to be contestants in All Stars Season 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(model_data_season_5[feature_cols_selected])\n",
    "\n",
    "predicted_contestants = list(model_data_season_5.loc[predictions==1]['Contestant'])\n",
    "all_stars_5_selected = ['Alexis Mateo', 'Blair St. Clair', 'Derrick Barry', 'India Ferrah', 'Jujubee',\n",
    "                        'Mariah Balenciaga', 'Mayhem Miller', 'Miz Cracker', 'Ongina', 'Shea Coulee']\n",
    "\n",
    "predicted_contestants_correct = [_ for _ in list(predicted_contestants) if _ in all_stars_5_selected]\n",
    "predicted_contestants_incorrect = [_ for _ in list(predicted_contestants) if _ not in all_stars_5_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shea Coulee', 'Miz Cracker', 'Blair St. Clair', 'Jujubee']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_contestants_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of incorrect predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Willam',\n",
       " 'Ivy Winters',\n",
       " 'Darienne Lake',\n",
       " 'Joslyn Fox',\n",
       " 'Trinity K. Bonet',\n",
       " 'Pearl',\n",
       " 'Jaidynn Diore Fierce',\n",
       " 'Acid Betty',\n",
       " 'Peppermint',\n",
       " 'Trinity the Tuck',\n",
       " 'Alexis Michelle',\n",
       " \"Nina Bo'nina Brown\",\n",
       " 'Eureka',\n",
       " 'Kameron Michaels',\n",
       " \"Asia O'Hara\",\n",
       " 'Brooke Lynn Hytes',\n",
       " \"A'Keria C. Davenport\",\n",
       " 'Silky Nutmeg Ganache',\n",
       " 'Nina West',\n",
       " 'Shuga Cain',\n",
       " 'Plastique Tiara',\n",
       " \"Ra'Jah O'Hara\",\n",
       " 'Yara Sofia',\n",
       " 'Katya',\n",
       " 'Roxxxy Andrews',\n",
       " \"Phi Phi O'Hara\",\n",
       " 'Kennedy Davenport',\n",
       " 'BeBe Zahara Benet',\n",
       " 'BenDeLaCreme',\n",
       " 'Monique Heart',\n",
       " 'Naomi Smalls',\n",
       " 'Valentina']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_contestants_incorrect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this looks like a long list of incorrect predictions and a few correct ones, it actually reveals a some gaps in my independent variables that might be useful for refining the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviewing sample output and refining the input parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the list of incorrect predictions, there are a few features noticeable to a regular viewer of the show that could inform how the model is further developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Prior All Stars competitors***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first noticeable feature of the incorrect predictions is that a high proportion of them had already competed in All Stars (notably Trinity the Tuck, who won the prior All Stars season). The reason that I had left previous All Stars competitors as possible competitors in future All Stars seasons is that it has happened in the past - Manila Luzon, Latrice Royale, Jujubee, and Alexis Mateo all competed in All Stars Season 1 and then again in either All Stars Season 4 or All Stars Season 5.\n",
    "\n",
    "The problem with this from a data perspective is that it biases the model heavily in favour of previous All Stars competitors, since it is their metrics than inform the original model. Additionally, they will have more appearances and placements by default, as a result of appearing on an additional season, and these tend to be correlated with selection. As a result, previous All Stars competitors are massively over-represented in the predicted competitors.\n",
    "\n",
    "The adjustment I will be making here is to make a contestant ineligible for future seasons if they have previously competed in any All Stars season, excluding All Stars Season 1. This is because all of the re-selected All Stars competitors so far are from All Stars Season 1, which was largely considered to be a particularly poor season (largely because of the convoluted teams format), so the re-selection of these contestants could be considered to be compensation for their participation in All Stars Season 1. No participants from All Stars Seasons 2-4 have been re-selected for another All Stars Season, so this makes sense for now, although this may have to be revisited if this changes in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ineligibility and declined invitations***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of reasons that a contestant may find themselves effectively ineligible for All Stars selection.\n",
    "\n",
    "Possible reasons that a contestant may be effectively ineligible for an All Stars invitation:\n",
    "- The contestant was disqualified for conduct outside the show (Sherry Pie, Season 12)\n",
    "- The contestant has had disagreements with the show/RuPaul (Pearl, Season 7; Willam, Season 4)\n",
    "- The contestant has since drag as a full-time/professional career (Ivy Winters, Season 5)\n",
    "- The contestant has since drag entirely (Tyra Sanchez, Season 2)\n",
    "- The contestant is now deceased (Sahara Davenport, Season 2)\n",
    "- The contestant is now judging and/or hosting a Drag Race spin-off (Brooke Lynn Hytes, Season 11, judge/host of Drag Race Canada)\n",
    "\n",
    "Additionally, a participant might receive an invitation for an All Stars season and then decline it. All Stars contestants Trinity the Tuck, Shea Coulee, Valentina, and Ben Delacreme have reportedly stated that they turned down an earlier All Stars invitation in order to compete on a later season, while Phi Phi O'Hara allegedly turned down an All Stars Season 1 invitation due to scheduling conflicts. Kim Chi and Laganja Estranja have also both said that they turned down an All Stars invitation previously. Additionally, Ben Delacreme and Adore Delano both voluntarily left the first All Stars seasons they competed in, likely lowering the chances of appearing in a subsequent season.\n",
    "\n",
    "None of this data can be easily obtained via a web scrape and any data relating to this would be effectively incomplete and unreliable compared to the season data (challenge wins, etc.) as it is effectively based on rumours and individual statements from the contestants, which can't be verified as production does not comment on who they have invited to partake in All Stars. Additionally, it is possible that there are other contestants who have been asked back for an All Stars season but have refrained from commenting on it publicly.\n",
    "\n",
    "As a metric, this is a difficult one to compile as the reasons are so varied and would be impossible to web-scrape without an overly complex algorithm that is beyond the scope of this project and for those reasons I had initially planned not to consider them in my analysis. However, this is clearly having an impact on the output and so I now think that it may be better for the output to filter out contestants known to be effectively ineligible, even though the data underlying this will be messy and incomplete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Popularity***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity with fans and success outside the show is usually a major factor in determining whether a contestant is selected for All Stars, even if the contestant does not perform outstandingly well by the episode metrics during their season (such as challenge wins). Examples include Trixie Mattel (who had a country music career and successful web series outside the show and was selected for, and subsequently won, All Stars Season 3) and Jasmine Masters (who had a short run on the show but found success on YouTube and was selected for All Stars 4).\n",
    "\n",
    "If you refer to the Pearson correlations tables, you will notice that, in both cases (untreated and over-sampled datasets), the independent variable with the strongest correlation and the lowest p-value is whether or not a contestant won Miss Congeniality in their original season. Prior to Season 10, the Miss Congeniality prize was voted by fans and this was notably controversial with Trinity the Tuck renaming the award as \"Fan Favourite\" in the Season 9 reunion. This incident brought about discussions that the award was more of a \"fan favourite\" in the cases of Pandora Boxx, Ben Delacreme, and Katya, where some felt that the Miss Congeniality winners were the most beloved by fans, even if there were more \"congenial\" contestants in their respective seasons. However, even after the Miss Congeniality award was voted by the other contestants, the season Miss Congeniality was consistently one of the season fan favourites regardless (Monet X Change, Nina West, and Heidi N Closet).\n",
    "\n",
    "However it is difficult to measure popularity by an objective metric. Follower counts on Instagram/Twitter might make a good proxy in this case, however I am not aware of a way to get follower counts prior to selection and additional season appearances will boost a contestant's following after airing, particularly in the case of contestants such as Manila Luzon (All Stars Season 4) and Shangela (All Stars Season 3), who had large gaps between their prior season and All Stars season appearances and experienced a surge of engagement with their social media after the airing of their respective All Stars seasons.\n",
    "\n",
    "The best metric for which historic data can be obtained that might serve as a proxy for popularity is probably Google Trends, which will show how many times a contestant's drag name has been searched prior to All Stars selection. This will involve creating some sort of web scraper to download the data for each contestant's normalized drag name.\n",
    "\n",
    "I will then take the highest score prior to a cut-off date specified for each All Stars Season. Other approaches would be either taking an \"area under the curve\" approach by summing the scores prior to the cut-off, or averaging the scores between the contestant's first appearance and the cut-off date, however, these might result in results that are either biased for or against contestants based on how long it had been since their first appearance. Taking the single highest Google Trends score for each contestant will not only be easier to implement, but should give a more reliable measure. Where contestants go by multiple names (e.g. Trinity the Tuck/Trinity Taylor), the highest score between the two names will be used.\n",
    "\n",
    "The other benefits of using Google Trends as opposed to social media followings is that it will prevent bias against controversial contestants, such as Roxxxy Andrews and Phi Phi O'Hara. These contestants were notably unpopular in their initial seasons, but were invited back to All Stars for a \"redemption\" story arc. Google Trends should measure contestants in terms of both popularity and controversy, both of which appear to be factors in being invited back for an All Stars season, whereas simply looking at social media metrics might measure only popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions and actions to take from sample output***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There appears to be a bias towards competitors of All Stars Seasons 2-4, despite none of these competitors appearing in subsequent seasons, so I will be removing these contestants from consideration for All Stars seasons that occur after their first All Stars appearance.\n",
    "- I will manually create a file of ineligible contestants for All Stars selection and create a function to remove these contestants' records from the seasons for which they are ineligible.\n",
    "- I will build another web scraper to download Google Trends data for contestants and another function to retrieve the highest Google Trends score for each contestant and add it as a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
